{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"display_name":"Yandex DataSphere Kernel","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"notebookId":"e7578c11-9e00-48dd-aaf7-66c3f49db909"},"cells":[{"cell_type":"markdown","source":"## Оценка качества STT моделей","metadata":{"cellId":"pdi41sd9ywggooxhxy7wlp"}},{"cell_type":"markdown","source":"Качество распознавания речи на имеющихся данных сильно зависит от выбора конкретной модели. Но чтобы можно было определить, какая из моделей лучше справляется с распознаванием под конкретный бизнес-кейс, требуется правильно построить систему оценки качества распознавания и определить соответствующие метрики.\n\nНаиболее популярной метрикой при оценке качества распознавания является метрика WER (Word Error Rate). Эта метрика оценивает похожесть полученного распознавания на некоторый \"эталонный\" пример, как правило получаемый с помощью разметки аудиозаписей с помощью асессоров. Проблема заключается в том, что значение этой метрики может очень сильно варьироваться не только от результатов распознавания, но также и от качества разметки аудиозаписей и самой методологии оценки.\n\nВ качестве примера можно привести популярную фразу \"алло\", которая может быть размечена как минимум четырьмя различными способами: \"алло\", \"алле\", \"ало\", \"але\". Также качество может падать, если пытаться различать буквы \"ё\" и \"е\", которые эквивалентны с точки зрения большинства моделей распознавания. Наконец, качество может очень сильно зависеть от того, требуется ли нам различать различные формы одних и тех же слов (к примеру, род, падежи существительных, времена глаголов и т.п.).\n\nПо этой причине мы решили предоставить пользователям свою небольшую библиотеку, которая позволит использовать метрики для оценки качества распознавания с учётом описанных особенностей. На текущий момент эта библиотека поддерживает вычисление метрики WER, однако в дальнейшем библиотеку планируется расширить и другими метриками.","metadata":{"cellId":"7k58oggvwatlffly4zs7ft"}},{"cell_type":"code","source":"from stt_metrics import WER, ClusterReferences\nfrom stt_metrics.text_transform import Lemmatizer","metadata":{"cellId":"wu2sr42o5dut1a288k6yo","trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Пример использования метрики WER\n\nРассмотрим самый простой вариант использования метрики WER:","metadata":{"cellId":"yc0598s63rmasktbb44rah"}},{"cell_type":"code","source":"reference = 'алло добрый день с моей карты только что списали крупную сумму денег хочу заблокировать её'\nhypothesis = 'але добрый день моей карты только что списал крупную суму денег хочу заблокировать ее'","metadata":{"cellId":"4y99e6d3ukju9e49pkxhsr","trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"wer = WER()\nwer_data = wer.get_metric_data(hyp=hypothesis, ref=reference)\nwer_value = wer.calculate_metric(wer_data)","metadata":{"cellId":"lvue2l49urq33ot90clyki","trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"`wer_data` &mdash; специальный объект, который хранит необходимую для вычисления WER информацию, а также предоставляет нам выравнивание двух текстов с указанием отличий. Последняя особенность может быть очень полезна при дальнейшем анализе отличий в распознавании и разметке.\n\nТак, на примере ниже мы видим, что значение метрики WER оказывается достаточно высоким. Однако многие ошибки для данного кейса оказываются довольно незначительными. Так, одна ошибка возникает из-за появившейся в разметке буквы \"ё\", ещё одна из ошибок связана с отличием в словах \"але\" и \"алло\", и ещё одна ошибка произошла из-за нераспознанного множественного числа глагола \"списал\".","metadata":{"cellId":"4m2uaxa0p3ubyimm0mwdie"}},{"cell_type":"code","source":"print(wer_data)\nprint(f'WER: {wer_value}')","metadata":{"cellId":"02las68bbbxjbfcg023x5w","trusted":true},"outputs":[{"name":"stdout","text":"{\n  errors: 5,\n  hyp_wc: 14,\n  ref_wc: 15,\n  diff_hyp: АЛЕ  добрый день * моей карты только что СПИСАЛ  крупную СУМУ  денег хочу заблокировать ЕЕ,\n  diff_ref: АЛЛО добрый день с моей карты только что СПИСАЛИ крупную СУММУ денег хочу заблокировать ЕЁ\n}\nWER: 0.3333333333333333\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### Избавление от ошибок\n\n#### Удаление артефактов\n\nОт возможных ошибок первого типа довольно просто избавиться, если заранее провалидировать имеющуюся разметку аудио и избавиться от возможных артефактов. В данном случае такой препроцессинг оказывается довольно простым, хотя в общем случае артефакты могут быть и куда менее очевидными.","metadata":{"cellId":"f3bp6agkr19g0p60fawjh"}},{"cell_type":"code","source":"def remove_artifacts(text):\n    return text.replace('ё', 'е')\n\n\nhypothesis, reference = remove_artifacts(hypothesis), remove_artifacts(reference)\n\nwer = WER()\nwer_data = wer.get_metric_data(hyp=hypothesis, ref=reference)\nwer_value = wer.calculate_metric(wer_data)\n\nprint(wer_data)\nprint(f'WER: {wer_value}')","metadata":{"cellId":"sifrl68bdficokkgpze9co","trusted":true},"outputs":[{"name":"stdout","text":"{\n  errors: 4,\n  hyp_wc: 14,\n  ref_wc: 15,\n  diff_hyp: АЛЕ  добрый день * моей карты только что СПИСАЛ  крупную СУМУ  денег хочу заблокировать ее,\n  diff_ref: АЛЛО добрый день с моей карты только что СПИСАЛИ крупную СУММУ денег хочу заблокировать ее\n}\nWER: 0.26666666666666666\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"#### ClusterReferences\n\nОшибки второго типа также могут быть довольно просто исключены, если явно указать наборы синонимичных фраз (ClusterReferences), которые следует воспринимать одинаково:","metadata":{"cellId":"c7bugxl9ftudswqm68cm6p"}},{"cell_type":"code","source":"cr = ClusterReferences()\ncr.add_cluster(center='алло', aliases=['ало', 'але', 'алле'])\n\nwer = WER(cr=cr)\nwer_data = wer.get_metric_data(hyp=hypothesis, ref=reference)\nwer_value = wer.calculate_metric(wer_data)\n\nprint(wer_data)\nprint(f'WER: {wer_value}')","metadata":{"cellId":"qs4zr12523lccn6a5gsy","trusted":true},"outputs":[{"name":"stdout","text":"{\n  errors: 3,\n  hyp_wc: 14,\n  ref_wc: 15,\n  diff_hyp: алло добрый день * моей карты только что СПИСАЛ  крупную СУМУ  денег хочу заблокировать ее,\n  diff_ref: алло добрый день с моей карты только что СПИСАЛИ крупную СУММУ денег хочу заблокировать ее\n}\nWER: 0.2\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"#### Lemmatizer\n\nНаконец, можно также постараться избавиться и от ошибок третьего типа, если привести все имеющиеся слова к их леммам. Тем не менее, делать это также следует аккуратно, потому что в лемматизации также могут нуждаться и фразы из ClusterReferences:","metadata":{"cellId":"a23rpn5h2cn7ndxwj68c"}},{"cell_type":"code","source":"lemmatizer = Lemmatizer()\nlemm_hypothesis, lemm_reference = lemmatizer.transform(hypothesis), lemmatizer.transform(reference)\n\nwer = WER(cr=cr)\nwer_data = wer.get_metric_data(hyp=lemm_hypothesis, ref=lemm_reference)\nwer_value = wer.calculate_metric(wer_data)\n\nprint(wer_data)\nprint(f'WER: {wer_value}')","metadata":{"cellId":"8hhjier6mvskvi6ndy0j9s","trusted":true},"outputs":[{"name":"stdout","text":"{\n  errors: 2,\n  hyp_wc: 14,\n  ref_wc: 15,\n  diff_hyp: алло добрый день * мой карта только что списать крупный СУМА  деньга хотеть заблокировать она,\n  diff_ref: алло добрый день с мой карта только что списать крупный СУММА деньга хотеть заблокировать она\n}\nWER: 0.13333333333333333\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### Выводы\n\nЕсли вам просто требуется проверить, что конкретная модель распознавания в среднем делает достаточно мало ошибок в словах, то простая версия метрики WER вполне может подойти вам.\n\nЕсли же вы используете эту метрику для сравнения поведения различных моделей на вашем бизнес-кейсе, то вам может также помочь:\n\n* Удаление из разметки и набор распознаваний явных артефактов, которые могут ухудшать значения используемых метрик, не влияя при этом на качество решения конкретной бизнес-задачи\n\n* Использование ClusterReference'ов для \"склейки\" одинаковых по сути распознаваний. Так можно склеить различные варианты распознавания фраз типа \"алло\", а также распознавания фраз с пробелами (наподобие \"контр страйк\" и \"контрстрайк\")\n\n* Лемматизация слов, если для нас не важны их окончания","metadata":{"cellId":"virjbqdb3crjuxif3vjlh"}},{"cell_type":"markdown","source":"## Пример использования метрики WER (агрегированный)\n\nПриведём ещё пример того, как просто посчитать значение метрики для нескольких записей.\n\nВоспользуемся для этого функцией `evaluate_wer`, которая считает WER сразу для большого набора текстов. \n\nЗаметим, что поскольку обычно в случае STT и гипотезы, и тексты разметки привязаны к конкрентым записям, которые в свою очередь имеют уникальные идентификаторы (в виде того же названия), то эта функция принимает на вход список текстов в виде словаря, где ключом является некоторый уникальный идентификатор, а значением &mdash; сам текст гипотезы/разметки.\n\nВыходом же этой функции является пара значений. Первое значение &mdash; среднее значение WER по всем переданным парам текстов. Второе значение &mdash; словарь, который для каждой пары текстов хранит соответствующий им WER, а также выравнивание текстов с указанием отличий.","metadata":{"cellId":"3vqxiwsiqo3hudfdgu7a6s"}},{"cell_type":"code","source":"from stt_metrics import evaluate_wer\n\n\nmean_wer, full_stats = evaluate_wer(\n    references={'wav1': 'один два', 'wav2': 'один два'},\n    hypotheses={'wav1': 'один три', 'wav2': 'один один три'},\n    cluster_references=None\n)","metadata":{"cellId":"89d2tvzxin4f1g7k4vbv5","trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"mean_wer","metadata":{"cellId":"3myn2xxvjl4vg5xfop67mj","trusted":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0.5833333333333333"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"full_stats","metadata":{"cellId":"pjn6dzyffyapdv7jtgvwz","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"{\n  \"id1\": {\n    \"metric_value\": 0.5,\n    \"metric_data\": {\n      \"errors\": 1,\n      \"hyp_wc\": 2,\n      \"ref_wc\": 2,\n      \"diff_hyp\": \"один ТРИ\",\n      \"diff_ref\": \"один ДВА\"\n    },\n    \"reference\": \"один два\",\n    \"hypothesis\": \"один три\"\n  },\n  \"id2\": {\n    \"metric_value\": 0.6666666666666666,\n    \"metric_data\": {\n      \"errors\": 2,\n      \"hyp_wc\": 3,\n      \"ref_wc\": 2,\n      \"diff_hyp\": \"один ОДИН три\",\n      \"diff_ref\": \"один ДВА  ***\"\n    },\n    \"reference\": \"один два\",\n    \"hypothesis\": \"один один три\"\n  }\n}\n"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"cellId":"amaya28zu2nytsry7zahih"},"outputs":[],"execution_count":null}]}